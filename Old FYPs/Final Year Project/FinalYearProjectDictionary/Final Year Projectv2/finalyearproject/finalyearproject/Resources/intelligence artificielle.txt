Un programme informatique est-il capable, à la manière d’un enfant, d’apprendre de son environnement ? S’il reste encore du chemin à parcourir, le machine learning, ou « apprentissage automatique », a connu des avancées significatives ces dernières années, poussé notamment par de grandes entreprises aux moyens inédits. Avec comme icône médiatique le Google Brain, qui a réussi la prouesse, en 2012, de découvrir le concept de chat en analysant des millions d’images issues du Web.
Nourrir le programme : un travail fastidieux
La technique la plus courante de machine learning est l’apprentissage supervisé : pour qu’un programme apprenne à reconnaître une voiture, par exemple, on le nourrit de dizaines de milliers d’images de voitures, étiquetées comme telles. Un entraînement qui nécessite des heures, voire des jours, avant que le programme puisse en repérer sur de nouvelles images.
Cette technique est relativement ancienne, mais elle a fait un bond avec les récentes avancées technologiques. La masse de données désormais disponibles ainsi que la puissance de calcul à disposition des ingénieurs multiplient l’efficacité des algorithmes.
Cette nouvelle génération d’apprentissage supervisé fait déjà partie de notre quotidien : les outils de traduction automatique en sont le parfait exemple. En analysant des immenses bases de données associant des textes et leur traduction, le programme relève des régularités statistiques, sur lesquelles il se fonde pour trouver la traduction la plus probable non seulement d’un mot, mais aussi d’une formule, voire d’une phrase.
Efficace, cette méthode atteint vite ses limites. « Ces machines sont bêtes, souligne Pierre-Yves Oudeyer, directeur de recherche en robotique et sciences cognitives à l’Institut national de recherche en informatique et en automatique. Elles ne comprennent rien aux phrases qu’elles traduisent, elles ont juste vu que telle phrase était souvent traduite de telle manière. » Qui plus est, elles nécessitent un travail fastidieux de la part des ingénieurs, chargés de concevoir les gigantesques bases de données pour nourrir leur apprentissage.
Quand une IA invente le concept de chat
Les chercheurs en intelligence artificielle s’emploient à dépasser ces limites, pour se rapprocher de l’apprentissage humain, comme l’explique Andrew Ng :
« Si vous réfléchissez à la façon dont les enfants apprennent à reconnaître les voitures, il n’existe aucun parent, aussi attentionné et patient soit-il, qui pointera du doigt 50 000 voitures. La plupart des neuroscientifiques pensent que pour apprendre les animaux et les enfants vont dans le monde et l’expérimentent par eux-mêmes. »
C’est sur cette idée que repose le projet de deep learning Google Brain, un réseau de neurones artificiels créé en connectant pas moins de 16 000 processeurs. En 2012, soit un an après son lancement, c’est ce programme qui avait réussi à découvrir le concept de chat. Concrètement, la machine a analysé, pendant trois jours, dix millions de captures d’écran de YouTube, choisies aléatoirement et non étiquetées. A l’issue de cet entraînement, le programme avait appris à détecter des têtes de chats et des corps humains – des formes récurrentes dans les images analysées.
